# SIMT 실행 모델

Warp/Wavefront, 점유율, GPU 최적화를 설명합니다.

---

## SIMT 개념

```
┌─────────────────────────────────────────────────────────────────┐
│                    SIMT (Single Instruction Multiple Threads)   │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  CPU (MIMD):                                                   │
│  ┌─────────┐ ┌─────────┐ ┌─────────┐ ┌─────────┐             │
│  │Thread 0 │ │Thread 1 │ │Thread 2 │ │Thread 3 │             │
│  │ ADD     │ │ MUL     │ │ SUB     │ │ DIV     │             │
│  │ (다른 명령어)                                             │             │
│  └─────────┘ └─────────┘ └─────────┘ └─────────┘             │
│                                                                 │
│  GPU (SIMT):                                                   │
│  ┌───────────────────────────────────────────────────────────┐ │
│  │              Warp (32 threads)                             │ │
│  │  ┌─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┐      │ │
│  │  │T0   │T1   │T2   │T3   │ ... │T29  │T30  │T31  │      │ │
│  │  │ ADD │ ADD │ ADD │ ADD │ ADD │ ADD │ ADD │ ADD │      │ │
│  │  │ (같은 명령어, 다른 데이터)                    │      │ │
│  │  └─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┘      │ │
│  └───────────────────────────────────────────────────────────┘ │
│                                                                 │
│  핵심: 32개 스레드가 동시에 같은 명령어 실행                  │
│  하지만 각자 다른 데이터(레지스터)에 대해 연산                │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

---

## Warp/Wavefront

```
┌─────────────────────────────────────────────────────────────────┐
│                    Warp 실행 모델                               │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  Thread Block (1024 threads 예시)                              │
│  ┌─────────────────────────────────────────────────────────┐   │
│  │                                                         │   │
│  │  ┌─────────────┐ ┌─────────────┐ ... ┌─────────────┐  │   │
│  │  │   Warp 0    │ │   Warp 1    │     │  Warp 31    │  │   │
│  │  │  (T0~T31)   │ │  (T32~T63)  │     │(T992~T1023) │  │   │
│  │  └─────────────┘ └─────────────┘     └─────────────┘  │   │
│  │                                                         │   │
│  │  1024 threads ÷ 32 threads/warp = 32 warps             │   │
│  └─────────────────────────────────────────────────────────┘   │
│                                                                 │
│  Warp 스케줄링:                                                │
│  ┌─────────────────────────────────────────────────────────┐   │
│  │ Cycle 1: Warp 0 명령어 발행                             │   │
│  │ Cycle 2: Warp 1 명령어 발행 (Warp 0은 메모리 대기)      │   │
│  │ Cycle 3: Warp 2 명령어 발행                             │   │
│  │ ...                                                     │   │
│  │ Cycle N: Warp 0 메모리 결과 도착, 다음 명령어 발행      │   │
│  └─────────────────────────────────────────────────────────┘   │
│                                                                 │
│  메모리 지연 숨기기: 한 Warp가 대기하면 다른 Warp 실행       │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

---

## Branch Divergence

```
┌─────────────────────────────────────────────────────────────────┐
│                    Branch Divergence                            │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  코드:                                                          │
│  if (threadIdx.x < 16) {                                       │
│      A();  // Thread 0-15                                      │
│  } else {                                                       │
│      B();  // Thread 16-31                                     │
│  }                                                             │
│                                                                 │
│  실행:                                                          │
│  ┌─────────────────────────────────────────────────────────┐   │
│  │ Warp (32 threads)                                       │   │
│  │                                                         │   │
│  │ Phase 1: A() 실행                                      │   │
│  │ ┌────┬────┬────┬────┬────┬────┬────┬────┐             │   │
│  │ │ T0 │ T1 │... │T15 │T16 │T17 │... │T31 │             │   │
│  │ │ A()│ A()│... │ A()│IDLE│IDLE│... │IDLE│             │   │
│  │ └────┴────┴────┴────┴────┴────┴────┴────┘             │   │
│  │ (T16~T31은 마스킹되어 실행 안 함)                      │   │
│  │                                                         │   │
│  │ Phase 2: B() 실행                                      │   │
│  │ ┌────┬────┬────┬────┬────┬────┬────┬────┐             │   │
│  │ │ T0 │ T1 │... │T15 │T16 │T17 │... │T31 │             │   │
│  │ │IDLE│IDLE│... │IDLE│ B()│ B()│... │ B()│             │   │
│  │ └────┴────┴────┴────┴────┴────┴────┴────┘             │   │
│  │ (T0~T15는 마스킹되어 실행 안 함)                       │   │
│  │                                                         │   │
│  │ 결과: 2배의 시간 소요! (순차 실행)                     │   │
│  └─────────────────────────────────────────────────────────┘   │
│                                                                 │
│  최악의 경우: 32개 스레드가 32개의 다른 경로                  │
│              → 32배 느려짐                                     │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

---

## Occupancy

```
┌─────────────────────────────────────────────────────────────────┐
│                    SM Occupancy                                 │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  Occupancy = 활성 Warp 수 / SM이 지원하는 최대 Warp 수        │
│                                                                 │
│  SM 자원 (예시):                                               │
│  • 최대 Warp: 64                                               │
│  • 레지스터: 65,536개                                          │
│  • Shared Memory: 48 KB                                        │
│                                                                 │
│  제한 요소 분석:                                               │
│  ┌─────────────────────────────────────────────────────────┐   │
│  │                                                         │   │
│  │ 1. 레지스터 제한                                       │   │
│  │    커널이 스레드당 128개 레지스터 사용:                │   │
│  │    65,536 ÷ 128 ÷ 32 = 16 warps 가능                  │   │
│  │    Occupancy = 16/64 = 25%                             │   │
│  │                                                         │   │
│  │ 2. Shared Memory 제한                                  │   │
│  │    커널이 Block당 16 KB 사용:                          │   │
│  │    48 KB ÷ 16 KB = 3 blocks 가능                      │   │
│  │    3 blocks × 8 warps/block = 24 warps                │   │
│  │    Occupancy = 24/64 = 37.5%                          │   │
│  │                                                         │   │
│  │ 최종 Occupancy = min(25%, 37.5%) = 25%                │   │
│  │                                                         │   │
│  └─────────────────────────────────────────────────────────┘   │
│                                                                 │
│  높은 Occupancy = 더 많은 Warp = 더 좋은 지연 숨기기          │
│  (항상 그런 것은 아님, 최적점 존재)                           │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

---

## Memory Coalescing

```
┌─────────────────────────────────────────────────────────────────┐
│                    Memory Coalescing                            │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  Coalesced Access (좋음):                                      │
│  ┌─────────────────────────────────────────────────────────┐   │
│  │ Warp 내 32 스레드가 연속 주소 접근:                     │   │
│  │                                                         │   │
│  │ T0 → addr[0]                                           │   │
│  │ T1 → addr[1]                                           │   │
│  │ T2 → addr[2]                                           │   │
│  │ ...                                                     │   │
│  │ T31 → addr[31]                                         │   │
│  │                                                         │   │
│  │ → 1번의 메모리 트랜잭션 (128 bytes)                    │   │
│  └─────────────────────────────────────────────────────────┘   │
│                                                                 │
│  Strided Access (나쁨):                                        │
│  ┌─────────────────────────────────────────────────────────┐   │
│  │ Warp 내 스레드가 떨어진 주소 접근:                      │   │
│  │                                                         │   │
│  │ T0 → addr[0]                                           │   │
│  │ T1 → addr[32]                                          │   │
│  │ T2 → addr[64]                                          │   │
│  │ ...                                                     │   │
│  │                                                         │   │
│  │ → 32번의 메모리 트랜잭션!                              │   │
│  └─────────────────────────────────────────────────────────┘   │
│                                                                 │
│  // 좋은 패턴                                                  │
│  data[threadIdx.x] = value;  // Coalesced                     │
│                                                                 │
│  // 나쁜 패턴                                                  │
│  data[threadIdx.x * stride] = value;  // Strided              │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

---

## GPU 최적화 전략

| 전략 | 설명 | 효과 |
|------|------|------|
| Branch 최소화 | Divergence 방지 | 처리량 향상 |
| Coalesced Access | 연속 메모리 접근 | 대역폭 활용 |
| Shared Memory | 자주 쓰는 데이터 캐싱 | 지연 감소 |
| 레지스터 최적화 | 변수 수 줄이기 | Occupancy 향상 |
| Warp 활용 | 충분한 병렬성 | 지연 숨기기 |

### 셰이더 최적화 예시

```hlsl
// 나쁜 예: Divergent Branch
if (Input.TexCoord.x < 0.5)
{
    // 복잡한 계산 A
}
else
{
    // 복잡한 계산 B
}

// 좋은 예: Branchless
float t = step(0.5, Input.TexCoord.x);
result = lerp(A, B, t);
```

---

## 참고 자료

- [NVIDIA CUDA Programming Guide](https://docs.nvidia.com/cuda/cuda-c-programming-guide/)
- [AMD GPU Architecture](https://www.amd.com/en/technologies/rdna-2)
- [Computer Architecture: A Quantitative Approach](https://www.elsevier.com/books/computer-architecture/hennessy/)
- [원본 문서 (timlly)](https://www.cnblogs.com/timlly/p/16964884.html)

